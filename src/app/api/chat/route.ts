import { query } from '@anthropic-ai/claude-agent-sdk'
import * as Sentry from '@sentry/nextjs'
import { metrics } from '@/lib/metrics'

const SYSTEM_PROMPT = `You are a helpful personal assistant designed to help with general research, questions, and tasks.

Your role is to:
- Answer questions on any topic accurately and thoroughly
- Help with research by searching the web for current information
- Assist with writing, editing, and brainstorming
- Provide explanations and summaries of complex topics
- Help solve problems and think through decisions

Guidelines:
- Be friendly, clear, and conversational
- Use web search when you need current information, facts you're unsure about, or real-time data
- Keep responses concise but complete - expand when the topic warrants depth
- Use markdown formatting when it helps readability (bullet points, code blocks, etc.)
- Be honest when you don't know something and offer to search for answers`

interface MessageInput {
  role: 'user' | 'assistant'
  content: string
}

export async function POST(request: Request) {
  const requestStartTime = Date.now()

  try {
    Sentry.addBreadcrumb({
      category: 'api',
      message: 'Chat API request received',
      level: 'info'
    })

    metrics.increment('api.chat.request', 1)

    const { messages } = await request.json() as { messages: MessageInput[] }

    if (!messages || !Array.isArray(messages)) {
      Sentry.captureMessage('Invalid chat request: missing messages array', {
        level: 'warning',
        tags: { endpoint: '/api/chat', error: 'validation' }
      })
      metrics.increment('api.chat.error', 1, {
        tags: { errorType: 'validation', reason: 'missing_messages' }
      })
      return new Response(
        JSON.stringify({ error: 'Messages array is required' }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      )
    }

    metrics.distribution('api.chat.message_count', messages.length)

    // Get the last user message
    const lastUserMessage = messages.filter(m => m.role === 'user').pop()
    if (!lastUserMessage) {
      Sentry.captureMessage('Invalid chat request: no user message found', {
        level: 'warning',
        tags: { endpoint: '/api/chat', error: 'validation' },
        extra: { messageCount: messages.length }
      })
      metrics.increment('api.chat.error', 1, {
        tags: { errorType: 'validation', reason: 'no_user_message' }
      })
      return new Response(
        JSON.stringify({ error: 'No user message found' }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      )
    }

    Sentry.captureMessage('Processing chat request', {
      level: 'info',
      tags: { endpoint: '/api/chat' },
      extra: {
        messageCount: messages.length,
        userMessageLength: lastUserMessage.content.length
      }
    })

    // Build conversation context
    const conversationContext = messages
      .slice(0, -1) // Exclude the last message since we pass it as the prompt
      .map((m: MessageInput) => `${m.role === 'user' ? 'User' : 'Assistant'}: ${m.content}`)
      .join('\n\n')

    const fullPrompt = conversationContext
      ? `${SYSTEM_PROMPT}\n\nPrevious conversation:\n${conversationContext}\n\nUser: ${lastUserMessage.content}`
      : `${SYSTEM_PROMPT}\n\nUser: ${lastUserMessage.content}`

    // Create a streaming response
    const encoder = new TextEncoder()
    const stream = new ReadableStream({
      async start(controller) {
        let streamStartTime = Date.now()
        let toolUsageCount = 0
        let textChunkCount = 0

        try {
          Sentry.addBreadcrumb({
            category: 'api',
            message: 'Starting Claude query stream',
            level: 'info'
          })

          // Use the claude-agent-sdk query function with all default tools enabled
          for await (const message of query({
            prompt: fullPrompt,
            options: {
              maxTurns: 10,
              // Use the preset to enable all Claude Code tools including WebSearch
              tools: { type: 'preset', preset: 'claude_code' },
              // Bypass all permission checks for automated tool execution
              permissionMode: 'bypassPermissions',
              allowDangerouslySkipPermissions: true,
              // Enable partial messages for real-time text streaming
              includePartialMessages: true,
              // Set working directory to the app's directory for sandboxing
              cwd: process.cwd(),
            }
          })) {
            // Handle streaming text deltas (partial messages)
            if (message.type === 'stream_event' && 'event' in message) {
              const event = message.event
              // Handle content block delta events for text streaming
              if (event.type === 'content_block_delta' && event.delta?.type === 'text_delta') {
                textChunkCount++
                controller.enqueue(encoder.encode(
                  `data: ${JSON.stringify({ type: 'text_delta', text: event.delta.text })}\n\n`
                ))
              }
            }

            // Send tool start events from assistant messages
            if (message.type === 'assistant' && 'message' in message) {
              const content = message.message?.content
              if (Array.isArray(content)) {
                for (const block of content) {
                  if (block.type === 'tool_use') {
                    toolUsageCount++
                    Sentry.addBreadcrumb({
                      category: 'api',
                      message: `Tool invoked: ${block.name}`,
                      level: 'info',
                      data: { toolName: block.name }
                    })
                    metrics.increment('api.chat.tool_used', 1, {
                      tags: { toolName: block.name }
                    })
                    controller.enqueue(encoder.encode(
                      `data: ${JSON.stringify({ type: 'tool_start', tool: block.name })}\n\n`
                    ))
                  }
                }
              }
            }

            // Send tool progress updates
            if (message.type === 'tool_progress') {
              controller.enqueue(encoder.encode(
                `data: ${JSON.stringify({ type: 'tool_progress', tool: message.tool_name, elapsed: message.elapsed_time_seconds })}\n\n`
              ))
            }

            // Signal completion
            if (message.type === 'result' && message.subtype === 'success') {
              const totalStreamTime = Date.now() - streamStartTime
              Sentry.captureMessage('Chat stream completed successfully', {
                level: 'info',
                tags: { endpoint: '/api/chat', result: 'success' },
                extra: {
                  streamDurationMs: totalStreamTime,
                  toolsUsed: toolUsageCount,
                  textChunks: textChunkCount
                }
              })
              metrics.distribution('api.chat.stream_duration', totalStreamTime, {
                unit: 'millisecond'
              })
              metrics.distribution('api.chat.tools_used', toolUsageCount)
              metrics.distribution('api.chat.text_chunks', textChunkCount)
              metrics.increment('api.chat.success', 1)
              controller.enqueue(encoder.encode(
                `data: ${JSON.stringify({ type: 'done' })}\n\n`
              ))
            }

            // Handle errors
            if (message.type === 'result' && message.subtype !== 'success') {
              Sentry.captureMessage('Chat query did not complete successfully', {
                level: 'error',
                tags: { endpoint: '/api/chat', result: message.subtype },
                extra: { messageType: message.type, subtype: message.subtype }
              })
              metrics.increment('api.chat.query_error', 1, {
                tags: { subtype: message.subtype }
              })
              controller.enqueue(encoder.encode(
                `data: ${JSON.stringify({ type: 'error', message: 'Query did not complete successfully' })}\n\n`
              ))
            }
          }

          controller.enqueue(encoder.encode('data: [DONE]\n\n'))
          controller.close()
        } catch (error) {
          console.error('Stream error:', error)
          Sentry.captureException(error, {
            tags: { endpoint: '/api/chat', error: 'stream' },
            extra: {
              toolUsageCount,
              textChunkCount,
              streamDurationMs: Date.now() - streamStartTime
            }
          })
          metrics.increment('api.chat.stream_error', 1)
          controller.enqueue(encoder.encode(
            `data: ${JSON.stringify({ type: 'error', message: 'Stream error occurred' })}\n\n`
          ))
          controller.close()
        }
      }
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })
  } catch (error) {
    console.error('Chat API error:', error)

    const requestDuration = Date.now() - requestStartTime
    Sentry.captureException(error, {
      tags: { endpoint: '/api/chat', error: 'unhandled' },
      extra: { requestDurationMs: requestDuration }
    })
    metrics.increment('api.chat.unhandled_error', 1)
    metrics.distribution('api.chat.error_response_time', requestDuration, {
      unit: 'millisecond'
    })

    return new Response(
      JSON.stringify({ error: 'Failed to process chat request. Check server logs for details.' }),
      { status: 500, headers: { 'Content-Type': 'application/json' } }
    )
  }
}
